import requests
import logging
from config.app_config import logger, OLLAMA_API
from services.instruction_templates import format_instruction_prompt


def generate_quiz_with_ollama(
    content,
    num_questions=5,
    model="llama3.1:8b-instruct-q4_0",
    question_type="multipleChoice",
    additional_instructions="",
):
    """
    Generate a quiz using Ollama with proper instruct formatting

    Args:
        content (str): Content to base the quiz on
        num_questions (int): Number of questions to generate
        model (str): LLM model to use (default: llama3.1:8b-instruct-q4_0)
        question_type (str): Type of questions (multipleChoice, trueFalse, shortAnswer, flashcards)
        additional_instructions (str): Additional instructions for the LLM

    Returns:
        str: Raw quiz text generated by the LLM
    """
    logger.info(f"Starting quiz generation with Ollama using {model}")

    # Limit content length for token constraints
    if len(content) > 128000:
        logger.warning("Content too long, truncating to 128,000 characters")
        content = content[:128000]

    # Use the instruction templates to format the prompt
    formatted_prompt = format_instruction_prompt(
        content=content,
        question_type=question_type,
        num_questions=num_questions,
        model_name=model,
        additional_instructions=additional_instructions,
    )

    # Log the formatted prompt for debugging (first 500 characters)
    logger.info(f"Formatted prompt preview: {formatted_prompt[:500]}...")

    # Prepare payload for Ollama API
    payload = {"model": model, "prompt": formatted_prompt, "stream": False}

    try:
        # Add timeout to the Ollama API call
        response = requests.post(
            OLLAMA_API, json=payload, timeout=300
        )  # 5-minute timeout

        if response.status_code == 200:
            # Get the full response
            response_json = response.json()
            raw_quiz = response_json.get("response", "No response received.")

            # Log the complete response
            logger.info("Ollama raw response:")
            logger.info(raw_quiz)

            # Also log information about tokens
            if "eval_count" in response_json:
                logger.info(f"Tokens used: {response_json.get('eval_count')}")
            if "eval_duration" in response_json:
                logger.info(f"Generation time: {response_json.get('eval_duration')}ns")

            return raw_quiz
        else:
            logger.error(f"Error from Ollama API: {response.status_code}")
            logger.error(response.text)
            return None
    except requests.exceptions.Timeout:
        logger.error("Timeout while calling Ollama API")
        return None
    except Exception as e:
        logger.error(f"Exception when calling Ollama API: {e}")
        return None
